{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tqdm\n",
      "  Downloading tqdm-4.56.0-py2.py3-none-any.whl (72 kB)\n",
      "\u001b[K     |████████████████████████████████| 72 kB 29 kB/s  eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: tqdm\n",
      "Successfully installed tqdm-4.56.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import _pickle as cPickle\n",
    "import gzip\n",
    "import os\n",
    "from sklearn.utils import shuffle\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility functions\n",
    "\n",
    "def one_hot_encoded(y, num_class):\n",
    "    n = y.shape[0]\n",
    "    onehot = np.zeros((n, num_class), dtype=\"int32\")\n",
    "    for i in range(n):\n",
    "        idx = y[i]\n",
    "        onehot[i][idx] = 1\n",
    "    return onehot\n",
    "\n",
    "\n",
    "def check_accuracy(y_true, y_pred):\n",
    "    return np.mean(y_pred == y_true)  # both are not one hot encoded\n",
    "\n",
    "\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x - x.max(axis = 1, keepdims=True)) #фиксим неустойчивость экспоненты\n",
    "    exp_x /= exp_x.sum(axis = 1, keepdims=True)\n",
    "    return exp_x\n",
    "    \n",
    "# l2 regularization\n",
    "def l2_reg(layers, lam=0.001):\n",
    "    reg_loss = 0.0\n",
    "    for layer in layers:\n",
    "        if hasattr(layer, 'W'):\n",
    "            reg_loss += 0.5 * lam * np.sum(layer.W * layer.W)\n",
    "    return reg_loss\n",
    "\n",
    "\n",
    "# l2 regularization grad\n",
    "def delta_l2_reg(layers, grads, lam=0.001):\n",
    "    for layer, grad in zip(layers, reversed(grads)):\n",
    "        if hasattr(layer, 'W'):\n",
    "            grad[0] += lam * layer.W\n",
    "    return grads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1., 0., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 2., 1.]]), array([[0.4223188 , 0.1553624 , 0.4223188 ],\n",
       "        [0.33333333, 0.33333333, 0.33333333],\n",
       "        [0.21194156, 0.57611688, 0.21194156]]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.ones((3, 3))\n",
    "x[:, 1] = np.arange(3)\n",
    "x, softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_numerical_gradient(f, x, verbose=False, h=0.00001):\n",
    "    \"\"\"Evaluates gradient df/dx via finite differences:\n",
    "    df/dx ~ (f(x+h) - f(x-h)) / 2h\n",
    "    Adopted from https://github.com/ddtm/dl-course/\n",
    "    \"\"\"\n",
    "    fx = f(x) # evaluate function value at original point\n",
    "    grad = np.zeros_like(x)\n",
    "    # iterate over all indexes in x\n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    while not it.finished:\n",
    "\n",
    "        # evaluate function at x+h\n",
    "        ix = it.multi_index\n",
    "        oldval = x[ix]\n",
    "        x[ix] = oldval + h # increment by h\n",
    "        fxph = f(x) # evalute f(x + h)\n",
    "        x[ix] = oldval - h\n",
    "        fxmh = f(x) # evaluate f(x - h)\n",
    "        x[ix] = oldval # restore\n",
    "\n",
    "        # compute the partial derivative with centered formula\n",
    "        grad[ix] = (fxph - fxmh) / (2 * h) # the slope\n",
    "        if verbose:\n",
    "            print (ix, grad[ix])\n",
    "        it.iternext() # step to next dimension\n",
    "\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU():\n",
    "    def __init__(self):\n",
    "        self.params = []\n",
    "        self.gradInput = None\n",
    "\n",
    "    def forward(self, X, mode):\n",
    "        self.X = X\n",
    "        return np.maximum(X, 0)\n",
    "    \n",
    "    def backward(self, dout, mode):\n",
    "        self.gradInput = dout.copy()\n",
    "        self.gradInput[self.X <= 0] = 0\n",
    "        return self.gradInput, []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "points = np.linspace(-1, 1, 10*12).reshape([10, 12])\n",
    "relu = ReLU()\n",
    "f = lambda x: relu.forward(x, mode='train').sum(axis=1).sum()\n",
    "res = f(points)\n",
    "numeric_grads = eval_numerical_gradient(f, points)\n",
    "print(numeric_grads)\n",
    "inp_grad = np.ones(shape=(10, 12))\n",
    "grads = relu.backward(inp_grad, mode='train')[0]\n",
    "assert np.allclose(grads, numeric_grads, rtol=1e-3, atol=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear():\n",
    "\n",
    "    def __init__(self, in_size, out_size):\n",
    "\n",
    "        # Xavier init\n",
    "        self.W = np.random.randn(in_size, out_size) / np.sqrt(in_size + out_size/ 2.)\n",
    "        self.b = np.zeros((1, out_size))\n",
    "        self.params = [self.W, self.b]\n",
    "        self.gradW = None\n",
    "        self.gradB = None\n",
    "        self.gradInput = None\n",
    "\n",
    "    def forward(self, X, mode):\n",
    "        self.X = X\n",
    "        return self.X.dot(self.W) + self.b\n",
    "    \n",
    "    def backward(self, dout, mode):\n",
    "        self.gradW = self.X.T.dot(dout)\n",
    "        self.gradB = np.mean(dout, axis = 0)\n",
    "        self.gradInput = dout.dot(self.W.T)\n",
    "        return self.gradInput, [self.gradW, self.gradB]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.57149177 -0.30378623  0.51355251 -0.05843785  0.79858359  0.64475902\n",
      "  -0.006915   -0.40036966 -0.0821716   0.3528353   0.73196141 -0.75795089]\n",
      " [-0.57149177 -0.30378623  0.51355251 -0.05843785  0.79858359  0.64475902\n",
      "  -0.006915   -0.40036966 -0.0821716   0.3528353   0.73196141 -0.75795089]\n",
      " [-0.57149177 -0.30378623  0.51355251 -0.05843785  0.79858359  0.64475902\n",
      "  -0.006915   -0.40036966 -0.0821716   0.3528353   0.73196141 -0.75795089]\n",
      " [-0.57149177 -0.30378623  0.51355251 -0.05843785  0.79858359  0.64475902\n",
      "  -0.006915   -0.40036966 -0.0821716   0.3528353   0.73196141 -0.75795089]\n",
      " [-0.57149177 -0.30378623  0.51355251 -0.05843785  0.79858359  0.64475902\n",
      "  -0.006915   -0.40036966 -0.0821716   0.3528353   0.73196141 -0.75795089]\n",
      " [-0.57149177 -0.30378623  0.51355251 -0.05843785  0.79858359  0.64475902\n",
      "  -0.006915   -0.40036966 -0.0821716   0.3528353   0.73196141 -0.75795089]\n",
      " [-0.57149177 -0.30378623  0.51355251 -0.05843785  0.79858359  0.64475902\n",
      "  -0.006915   -0.40036966 -0.0821716   0.3528353   0.73196141 -0.75795089]\n",
      " [-0.57149177 -0.30378623  0.51355251 -0.05843785  0.79858359  0.64475902\n",
      "  -0.006915   -0.40036966 -0.0821716   0.3528353   0.73196141 -0.75795089]\n",
      " [-0.57149177 -0.30378623  0.51355251 -0.05843785  0.79858359  0.64475902\n",
      "  -0.006915   -0.40036966 -0.0821716   0.3528353   0.73196141 -0.75795089]\n",
      " [-0.57149177 -0.30378623  0.51355251 -0.05843785  0.79858359  0.64475902\n",
      "  -0.006915   -0.40036966 -0.0821716   0.3528353   0.73196141 -0.75795089]]\n"
     ]
    }
   ],
   "source": [
    "points = np.linspace(-1, 1, 10*12).reshape([10, 12])\n",
    "relu = Linear(12, 5)\n",
    "f = lambda x: relu.forward(x, mode='train').sum(axis=1).sum()\n",
    "res = f(points)\n",
    "numeric_grads = eval_numerical_gradient(f, points)\n",
    "print(numeric_grads)\n",
    "inp_grad = np.ones(shape=(10, 5))\n",
    "grads = relu.backward(inp_grad, mode='train')[0]\n",
    "assert np.allclose(grads, numeric_grads, rtol=1e-3, atol=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEntropyLoss(object):\n",
    "\n",
    "    def forward(self, X, y):\n",
    "        self.n = y.shape[0]\n",
    "        self.p = softmax(X)\n",
    "        ce = - np.sum(np.log(self.p[np.arange(self.n), y])) / self.n\n",
    "        return ce\n",
    "    \n",
    "    def backward(self, X, y):\n",
    "        dx = self.p.copy()\n",
    "        dx[np.arange(self.n), y] -= 1\n",
    "        dx /= self.n\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.31122967, -0.31122967],\n",
       "       [-0.13644589,  0.13644589]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ce = CrossEntropyLoss()\n",
    "x = np.array([[0.75, 0.25], [0.99, 0.01]])\n",
    "y = np.array([1, 0]).T\n",
    "ce.forward(x, y)\n",
    "ce.backward(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN:\n",
    "\n",
    "    def __init__(self, loss_func=CrossEntropyLoss(), mode = 'train'):\n",
    "    \n",
    "        self.layers = []\n",
    "        self.params = []\n",
    "        self.loss_func = loss_func\n",
    "        self.grads = []\n",
    "        self.mode = mode\n",
    "\n",
    "    def add_layer(self,layer):\n",
    "        self.layers.append(layer)\n",
    "        self.params.append(layer.params)\n",
    "\n",
    "    def forward(self, X):\n",
    "        for layer in self.layers:\n",
    "            X = layer.forward(X, self.mode)\n",
    "        return X\n",
    "\n",
    "    def backward(self, dout):\n",
    "        self.clear_grad_param()\n",
    "        for layer in reversed(self.layers):\n",
    "            dout, grad = layer.backward(dout, self.mode)\n",
    "            self.grads.append(grad)\n",
    "        return self.grads\n",
    "\n",
    "    def train_step(self, X, y):\n",
    "        out = self.forward(X)\n",
    "        loss = self.loss_func.forward(out,y)\n",
    "        dout = self.loss_func.backward(out,y)\n",
    "        loss += l2_reg(self.layers)\n",
    "        grads = self.backward(dout)\n",
    "        grads = delta_l2_reg(self.layers, grads)\n",
    "        return loss, grads\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = self.forward(X)\n",
    "        return np.argmax(softmax(X), axis=1)\n",
    "\n",
    "\n",
    "    def dispGradParam():\n",
    "        print(self.grads)\n",
    "    \n",
    "\n",
    "    def clear_grad_param(self):\n",
    "        self.grads = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD with momentum\n",
    "def update(velocity, params, grads, learning_rate=0.001, mu=0.9):\n",
    "    for v, p, g, in zip(velocity, params, reversed(grads)):\n",
    "        for i in range(len(g)):\n",
    "            v[i] = mu * v[i] + learning_rate * g[i]\n",
    "            p[i] -= v[i]\n",
    "\n",
    "\n",
    "# get minibatches\n",
    "def minibatch(X, y, minibatch_size):\n",
    "    n = X.shape[0]\n",
    "    minibatches = []\n",
    "    X, y = shuffle(X, y)\n",
    "\n",
    "    for i in range(0, n , minibatch_size):\n",
    "        X_batch = X[i:i + minibatch_size, ...]\n",
    "        y_batch = y[i:i + minibatch_size, ...]\n",
    "\n",
    "        minibatches.append((X_batch, y_batch))\n",
    "    return minibatches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, X_train, y_train, minibatch_size, epoch, learning_rate, mu=0.9,\n",
    "                 verbose=True, X_val=None, y_val=None, nesterov=True):\n",
    "    val_loss_epoch = []\n",
    "    minibatches = minibatch(X_train, y_train, minibatch_size)\n",
    "    minibatches_val = minibatch(X_val, y_val, minibatch_size)\n",
    "\n",
    "    c = 0 \n",
    "    for i in range(epoch):\n",
    "        loss_batch = []\n",
    "        val_loss_batch = []\n",
    "        velocity = []\n",
    "        for param_layer in net.params:\n",
    "            p = [np.zeros_like(param) for param in list(param_layer)]\n",
    "            velocity.append(p)\n",
    "\n",
    "        if verbose:\n",
    "            print(\"Epoch {0}\".format(i + 1))\n",
    "\n",
    "        # iterate over mini batches\n",
    "        for X_mini, y_mini in tqdm(minibatches):\n",
    "\n",
    "            loss, grads = net.train_step(X_mini, y_mini)\n",
    "            loss_batch.append(loss)\n",
    "            update(velocity, net.params, grads,\n",
    "                            learning_rate=learning_rate, mu=mu)\n",
    "\n",
    "        for X_mini_val, y_mini_val in tqdm(minibatches_val):\n",
    "            val_loss, _ = net.train_step(X_mini, y_mini)\n",
    "            val_loss_batch.append(val_loss)\n",
    "\n",
    "\n",
    "        # accuracy of model at end of epoch after all mini batch updates   \n",
    "\n",
    "        if verbose:\n",
    "            m_train = X_train.shape[0]\n",
    "            m_val = X_val.shape[0]\n",
    "            y_train_pred = np.array([], dtype=\"int64\")\n",
    "            y_val_pred = np.array([], dtype=\"int64\")\n",
    "\n",
    "            for i in range(0, m_train, minibatch_size):\n",
    "                X_tr = X_train[i:i + minibatch_size, : ]\n",
    "                y_tr = y_train[i:i + minibatch_size, ]\n",
    "                y_train_pred = np.append(y_train_pred, net.predict(X_tr))\n",
    "\n",
    "            for i in range(0, m_val, minibatch_size):\n",
    "                X_va = X_val[i:i + minibatch_size, : ]\n",
    "                y_va = y_val[i:i + minibatch_size, ]\n",
    "                y_val_pred = np.append(y_val_pred, net.predict(X_va))\n",
    "\n",
    "            train_acc = check_accuracy(y_train, y_train_pred)\n",
    "            val_acc = check_accuracy(y_val, y_val_pred)\n",
    "\n",
    "            mean_train_loss = sum(loss_batch) / float(len(loss_batch))\n",
    "            mean_val_loss = sum(val_loss_batch) / float(len(val_loss_batch))\n",
    "\n",
    "\n",
    "            # early stopping with patience = 5 on val loss\n",
    "\n",
    "            if len(val_loss_epoch) == 0:\n",
    "                val_loss_epoch.append(mean_val_loss)\n",
    "            else:\n",
    "                for j in val_loss_epoch[-5:]:\n",
    "                    if mean_val_loss > j:\n",
    "                        c += 1\n",
    "                    else:\n",
    "                        c = 0\n",
    "                if c > 5:\n",
    "                    print('Early stopping')\n",
    "                    return net\n",
    "                else:\n",
    "                    c = 0\n",
    "                    val_loss_epoch.append(mean_val_loss)    \n",
    "\n",
    "\n",
    "            print(\"Loss = {0} | Training Accuracy = {1} | Val Loss = {2} | Val Accuracy = {3}\".format(\n",
    "                mean_train_loss, train_acc, mean_val_loss, val_acc))\n",
    "    return net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 786.48it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 620.37it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 703.27it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 698.93it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 893.93it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 691.79it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 810.65it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 666.82it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 838.36it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 868.39it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 541.69it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 739.48it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1066.71it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 605.94it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 501.89it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 851.12it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1175.86it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 558.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 733.40it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 647.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 803.35it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 905.90it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 895.64it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 858.61it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 758.46it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 741.83it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 797.40it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 748.98it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 906.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 753.15it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 552.46it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 767.34it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1159.29it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 803.66it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 670.34it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 708.86it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 804.89it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 631.48it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 724.78it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 699.52it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1339.18it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1137.28it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1216.09it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1069.43it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 971.35it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 888.25it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 933.73it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 935.60it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 886.37it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1062.12it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1069.16it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 4)\n",
      "(4, 4)\n",
      "Epoch 1\n",
      "Loss = 0.861972406955323 | Training Accuracy = 0.5 | Val Loss = 0.6851584228688161 | Val Accuracy = 0.5\n",
      "Epoch 2\n",
      "Loss = 0.6851584228688161 | Training Accuracy = 0.5 | Val Loss = 0.6813526747116484 | Val Accuracy = 0.5\n",
      "Epoch 3\n",
      "Loss = 0.6813526747116484 | Training Accuracy = 0.5 | Val Loss = 0.6791504797868688 | Val Accuracy = 0.5\n",
      "Epoch 4\n",
      "Loss = 0.6791504797868688 | Training Accuracy = 0.5 | Val Loss = 0.6770894170266254 | Val Accuracy = 0.5\n",
      "Epoch 5\n",
      "Loss = 0.6770894170266254 | Training Accuracy = 0.5 | Val Loss = 0.6751259453096258 | Val Accuracy = 0.5\n",
      "Epoch 6\n",
      "Loss = 0.6751259453096258 | Training Accuracy = 0.5 | Val Loss = 0.6732226767352216 | Val Accuracy = 0.5\n",
      "Epoch 7\n",
      "Loss = 0.6732226767352216 | Training Accuracy = 0.5 | Val Loss = 0.6713744932470034 | Val Accuracy = 0.5\n",
      "Epoch 8\n",
      "Loss = 0.6713744932470034 | Training Accuracy = 0.5 | Val Loss = 0.6695612814562377 | Val Accuracy = 0.5\n",
      "Epoch 9\n",
      "Loss = 0.6695612814562377 | Training Accuracy = 0.5 | Val Loss = 0.6677741574086572 | Val Accuracy = 0.5\n",
      "Epoch 10\n",
      "Loss = 0.6677741574086572 | Training Accuracy = 0.5 | Val Loss = 0.666002660784451 | Val Accuracy = 0.5\n",
      "Epoch 11\n",
      "Loss = 0.666002660784451 | Training Accuracy = 0.5 | Val Loss = 0.6642506424869722 | Val Accuracy = 0.5\n",
      "Epoch 12\n",
      "Loss = 0.6642506424869722 | Training Accuracy = 0.5 | Val Loss = 0.6625157712667489 | Val Accuracy = 0.5\n",
      "Epoch 13\n",
      "Loss = 0.6625157712667489 | Training Accuracy = 0.5 | Val Loss = 0.660798754764089 | Val Accuracy = 0.5\n",
      "Epoch 14\n",
      "Loss = 0.660798754764089 | Training Accuracy = 0.5 | Val Loss = 0.6590737749940355 | Val Accuracy = 0.5\n",
      "Epoch 15\n",
      "Loss = 0.6590737749940355 | Training Accuracy = 0.5 | Val Loss = 0.657358331078467 | Val Accuracy = 0.5\n",
      "Epoch 16\n",
      "Loss = 0.657358331078467 | Training Accuracy = 0.5 | Val Loss = 0.6556475974262258 | Val Accuracy = 0.5\n",
      "Epoch 17\n",
      "Loss = 0.6556475974262258 | Training Accuracy = 0.5 | Val Loss = 0.6539402559251146 | Val Accuracy = 0.5\n",
      "Epoch 18\n",
      "Loss = 0.6539402559251146 | Training Accuracy = 0.5 | Val Loss = 0.65223521464137 | Val Accuracy = 0.5\n",
      "Epoch 19\n",
      "Loss = 0.65223521464137 | Training Accuracy = 0.5 | Val Loss = 0.6505263556937755 | Val Accuracy = 0.5\n",
      "Epoch 20\n",
      "Loss = 0.6505263556937755 | Training Accuracy = 0.5 | Val Loss = 0.6487860977938006 | Val Accuracy = 0.5\n",
      "Epoch 21\n",
      "Loss = 0.6487860977938006 | Training Accuracy = 0.5 | Val Loss = 0.6470767133112442 | Val Accuracy = 0.5\n",
      "Epoch 22\n",
      "Loss = 0.6470767133112442 | Training Accuracy = 0.5 | Val Loss = 0.6453671718971664 | Val Accuracy = 0.5\n",
      "Epoch 23\n",
      "Loss = 0.6453671718971664 | Training Accuracy = 0.5 | Val Loss = 0.643656272055698 | Val Accuracy = 0.5\n",
      "Epoch 24\n",
      "Loss = 0.643656272055698 | Training Accuracy = 0.5 | Val Loss = 0.6419435383211007 | Val Accuracy = 0.5\n",
      "Epoch 25\n",
      "Loss = 0.6419435383211007 | Training Accuracy = 0.5 | Val Loss = 0.6402285309308131 | Val Accuracy = 0.5\n",
      "Epoch 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1204.22it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 876.19it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 915.59it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 932.69it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1012.63it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1560.96it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 598.16it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 813.95it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 993.20it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1086.33it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1234.34it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 849.91it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 633.10it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 787.96it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 627.33it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1066.17it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 886.93it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 826.79it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 701.15it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 979.98it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 734.81it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1275.25it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 645.58it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 923.86it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 844.26it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 828.91it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 811.59it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 813.80it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 773.00it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 630.72it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 746.18it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 747.12it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 567.03it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 606.46it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 953.03it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1302.58it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 831.21it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 886.93it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 517.24it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 704.57it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 417.01it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1062.66it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 639.28it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 795.58it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 640.74it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1004.86it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 816.49it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 920.41it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 338.77it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 762.74it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 589.83it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 0.6402285309308131 | Training Accuracy = 0.5 | Val Loss = 0.6385108378418449 | Val Accuracy = 0.5\n",
      "Epoch 27\n",
      "Loss = 0.6385108378418449 | Training Accuracy = 0.5 | Val Loss = 0.636790068753846 | Val Accuracy = 0.5\n",
      "Epoch 28\n",
      "Loss = 0.636790068753846 | Training Accuracy = 0.5 | Val Loss = 0.6350658503861387 | Val Accuracy = 0.5\n",
      "Epoch 29\n",
      "Loss = 0.6350658503861387 | Training Accuracy = 0.5 | Val Loss = 0.6333378227377764 | Val Accuracy = 0.5\n",
      "Epoch 30\n",
      "Loss = 0.6333378227377764 | Training Accuracy = 0.5 | Val Loss = 0.6316050219278943 | Val Accuracy = 0.5\n",
      "Epoch 31\n",
      "Loss = 0.6316050219278943 | Training Accuracy = 0.5 | Val Loss = 0.6298406330804069 | Val Accuracy = 0.5\n",
      "Epoch 32\n",
      "Loss = 0.6298406330804069 | Training Accuracy = 0.5 | Val Loss = 0.6280859157611253 | Val Accuracy = 0.5\n",
      "Epoch 33\n",
      "Loss = 0.6280859157611253 | Training Accuracy = 0.5 | Val Loss = 0.6263302856982255 | Val Accuracy = 0.5\n",
      "Epoch 34\n",
      "Loss = 0.6263302856982255 | Training Accuracy = 0.5 | Val Loss = 0.6245694634144902 | Val Accuracy = 0.5\n",
      "Epoch 35\n",
      "Loss = 0.6245694634144902 | Training Accuracy = 0.5 | Val Loss = 0.6228308932467446 | Val Accuracy = 0.5\n",
      "Epoch 36\n",
      "Loss = 0.6228308932467446 | Training Accuracy = 0.5 | Val Loss = 0.6211259110497751 | Val Accuracy = 0.5\n",
      "Epoch 37\n",
      "Loss = 0.6211259110497751 | Training Accuracy = 0.5 | Val Loss = 0.6193058478468529 | Val Accuracy = 0.5\n",
      "Epoch 38\n",
      "Loss = 0.6193058478468529 | Training Accuracy = 0.5 | Val Loss = 0.6175138533594582 | Val Accuracy = 0.5\n",
      "Epoch 39\n",
      "Loss = 0.6175138533594582 | Training Accuracy = 0.5 | Val Loss = 0.6157168249231918 | Val Accuracy = 0.5\n",
      "Epoch 40\n",
      "Loss = 0.6157168249231918 | Training Accuracy = 0.5 | Val Loss = 0.6139138631650455 | Val Accuracy = 0.5\n",
      "Epoch 41\n",
      "Loss = 0.6139138631650455 | Training Accuracy = 0.5 | Val Loss = 0.6121042799430918 | Val Accuracy = 0.5\n",
      "Epoch 42\n",
      "Loss = 0.6121042799430918 | Training Accuracy = 0.5 | Val Loss = 0.6102874716157113 | Val Accuracy = 0.5\n",
      "Epoch 43\n",
      "Loss = 0.6102874716157113 | Training Accuracy = 0.5 | Val Loss = 0.608462898502813 | Val Accuracy = 0.5\n",
      "Epoch 44\n",
      "Loss = 0.608462898502813 | Training Accuracy = 0.5 | Val Loss = 0.60663019073702 | Val Accuracy = 0.5\n",
      "Epoch 45\n",
      "Loss = 0.60663019073702 | Training Accuracy = 0.5 | Val Loss = 0.6047896663489527 | Val Accuracy = 0.5\n",
      "Epoch 46\n",
      "Loss = 0.6047896663489527 | Training Accuracy = 0.5 | Val Loss = 0.6029389974938987 | Val Accuracy = 0.5\n",
      "Epoch 47\n",
      "Loss = 0.6029389974938987 | Training Accuracy = 0.5 | Val Loss = 0.601078847702452 | Val Accuracy = 0.5\n",
      "Epoch 48\n",
      "Loss = 0.601078847702452 | Training Accuracy = 0.5 | Val Loss = 0.5992087646574625 | Val Accuracy = 0.5\n",
      "Epoch 49\n",
      "Loss = 0.5992087646574625 | Training Accuracy = 0.5 | Val Loss = 0.5973283664764757 | Val Accuracy = 0.5\n",
      "Epoch 50\n",
      "Loss = 0.5973283664764757 | Training Accuracy = 0.5 | Val Loss = 0.5954372796819062 | Val Accuracy = 0.5\n",
      "Epoch 51\n",
      "Loss = 0.5954372796819062 | Training Accuracy = 0.5 | Val Loss = 0.5935351359909549 | Val Accuracy = 0.5\n",
      "Epoch 52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 716.61it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 636.75it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 514.20it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1484.18it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1035.12it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 762.18it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 667.46it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 656.59it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 915.39it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 756.68it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 598.08it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 760.53it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 905.70it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 816.17it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 739.61it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 882.45it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 804.59it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 628.83it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 442.30it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 852.15it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 906.68it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 434.69it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 611.50it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 821.61it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 866.41it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 604.45it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 447.01it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1068.34it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 779.47it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1009.95it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 528.65it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 651.69it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 719.56it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 702.92it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 871.63it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 899.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 493.10it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 637.34it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 795.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 862.67it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 709.70it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 526.86it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 625.64it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 831.21it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 612.31it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 743.67it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 611.41it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 679.24it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 680.23it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 582.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 0.5935351359909549 | Training Accuracy = 0.5 | Val Loss = 0.591619960115599 | Val Accuracy = 0.5\n",
      "Epoch 53\n",
      "Loss = 0.591619960115599 | Training Accuracy = 0.5 | Val Loss = 0.5896691437456054 | Val Accuracy = 0.5\n",
      "Epoch 54\n",
      "Loss = 0.5896691437456054 | Training Accuracy = 0.5 | Val Loss = 0.5877269479513193 | Val Accuracy = 0.5\n",
      "Epoch 55\n",
      "Loss = 0.5877269479513193 | Training Accuracy = 0.5 | Val Loss = 0.5857732636520206 | Val Accuracy = 0.5\n",
      "Epoch 56\n",
      "Loss = 0.5857732636520206 | Training Accuracy = 0.5 | Val Loss = 0.5838068081570159 | Val Accuracy = 0.5\n",
      "Epoch 57\n",
      "Loss = 0.5838068081570159 | Training Accuracy = 0.5 | Val Loss = 0.5818271844568323 | Val Accuracy = 0.5\n",
      "Epoch 58\n",
      "Loss = 0.5818271844568323 | Training Accuracy = 0.5 | Val Loss = 0.5798340274152846 | Val Accuracy = 0.5\n",
      "Epoch 59\n",
      "Loss = 0.5798340274152846 | Training Accuracy = 0.5 | Val Loss = 0.5778282427919779 | Val Accuracy = 0.5\n",
      "Epoch 60\n",
      "Loss = 0.5778282427919779 | Training Accuracy = 0.5 | Val Loss = 0.5758104704534556 | Val Accuracy = 0.5\n",
      "Epoch 61\n",
      "Loss = 0.5758104704534556 | Training Accuracy = 0.5 | Val Loss = 0.5737729446437385 | Val Accuracy = 0.5\n",
      "Epoch 62\n",
      "Loss = 0.5737729446437385 | Training Accuracy = 0.5 | Val Loss = 0.5717235347638641 | Val Accuracy = 0.5\n",
      "Epoch 63\n",
      "Loss = 0.5717235347638641 | Training Accuracy = 0.5 | Val Loss = 0.5696582171217154 | Val Accuracy = 0.5\n",
      "Epoch 64\n",
      "Loss = 0.5696582171217154 | Training Accuracy = 0.5 | Val Loss = 0.567576171026464 | Val Accuracy = 0.5\n",
      "Epoch 65\n",
      "Loss = 0.567576171026464 | Training Accuracy = 0.5 | Val Loss = 0.5654781774609989 | Val Accuracy = 0.5\n",
      "Epoch 66\n",
      "Loss = 0.5654781774609989 | Training Accuracy = 0.5 | Val Loss = 0.5633636925212797 | Val Accuracy = 0.5\n",
      "Epoch 67\n",
      "Loss = 0.5633636925212797 | Training Accuracy = 0.5 | Val Loss = 0.5612323174493435 | Val Accuracy = 0.5\n",
      "Epoch 68\n",
      "Loss = 0.5612323174493435 | Training Accuracy = 0.5 | Val Loss = 0.5590836657480163 | Val Accuracy = 0.5\n",
      "Epoch 69\n",
      "Loss = 0.5590836657480163 | Training Accuracy = 0.5 | Val Loss = 0.556917350654324 | Val Accuracy = 0.5\n",
      "Epoch 70\n",
      "Loss = 0.556917350654324 | Training Accuracy = 0.5 | Val Loss = 0.5547329840621518 | Val Accuracy = 0.5\n",
      "Epoch 71\n",
      "Loss = 0.5547329840621518 | Training Accuracy = 0.5 | Val Loss = 0.552530176457817 | Val Accuracy = 0.5\n",
      "Epoch 72\n",
      "Loss = 0.552530176457817 | Training Accuracy = 0.5 | Val Loss = 0.5503085371181379 | Val Accuracy = 0.5\n",
      "Epoch 73\n",
      "Loss = 0.5503085371181379 | Training Accuracy = 0.5 | Val Loss = 0.5480676742860271 | Val Accuracy = 0.5\n",
      "Epoch 74\n",
      "Loss = 0.5480676742860271 | Training Accuracy = 0.5 | Val Loss = 0.5458085967344213 | Val Accuracy = 0.5\n",
      "Epoch 75\n",
      "Loss = 0.5458085967344213 | Training Accuracy = 0.5 | Val Loss = 0.5435302181231457 | Val Accuracy = 0.5\n",
      "Epoch 76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 583.27it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1141.62it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 201.21it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 875.45it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 873.63it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 665.23it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 536.56it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 687.25it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 813.16it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 497.43it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 635.02it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 676.83it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 743.41it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 680.01it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 567.72it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 582.38it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1034.61it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 951.95it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 722.04it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 803.81it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 916.99it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1029.53it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 860.19it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 549.71it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 760.80it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 951.52it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1033.08it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 144.93it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 964.43it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 948.72it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 558.27it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 572.60it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 911.41it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1021.01it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 792.28it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 602.46it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 824.19it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 957.60it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1052.26it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 581.81it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 661.15it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 887.50it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 992.50it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 166.50it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 901.23it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 766.92it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 532.27it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 597.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 0.5435302181231457 | Training Accuracy = 0.5 | Val Loss = 0.5412292860422421 | Val Accuracy = 0.5\n",
      "Epoch 77\n",
      "Loss = 0.5412292860422421 | Training Accuracy = 0.5 | Val Loss = 0.5389077100235458 | Val Accuracy = 0.5\n",
      "Epoch 78\n",
      "Loss = 0.5389077100235458 | Training Accuracy = 0.5 | Val Loss = 0.5365649893945783 | Val Accuracy = 0.5\n",
      "Epoch 79\n",
      "Loss = 0.5365649893945783 | Training Accuracy = 0.5 | Val Loss = 0.5342006987257282 | Val Accuracy = 0.5\n",
      "Epoch 80\n",
      "Loss = 0.5342006987257282 | Training Accuracy = 0.5 | Val Loss = 0.5318144435673765 | Val Accuracy = 0.5\n",
      "Epoch 81\n",
      "Loss = 0.5318144435673765 | Training Accuracy = 0.5 | Val Loss = 0.5294058302053819 | Val Accuracy = 0.5\n",
      "Epoch 82\n",
      "Loss = 0.5294058302053819 | Training Accuracy = 1.0 | Val Loss = 0.5269744716281756 | Val Accuracy = 1.0\n",
      "Epoch 83\n",
      "Loss = 0.5269744716281756 | Training Accuracy = 1.0 | Val Loss = 0.5245199812926895 | Val Accuracy = 1.0\n",
      "Epoch 84\n",
      "Loss = 0.5245199812926895 | Training Accuracy = 1.0 | Val Loss = 0.5220419770940158 | Val Accuracy = 1.0\n",
      "Epoch 85\n",
      "Loss = 0.5220419770940158 | Training Accuracy = 1.0 | Val Loss = 0.5195400793596877 | Val Accuracy = 1.0\n",
      "Epoch 86\n",
      "Loss = 0.5195400793596877 | Training Accuracy = 1.0 | Val Loss = 0.5170139130763474 | Val Accuracy = 1.0\n",
      "Epoch 87\n",
      "Loss = 0.5170139130763474 | Training Accuracy = 1.0 | Val Loss = 0.5144631072998174 | Val Accuracy = 1.0\n",
      "Epoch 88\n",
      "Loss = 0.5144631072998174 | Training Accuracy = 1.0 | Val Loss = 0.5119259407543076 | Val Accuracy = 1.0\n",
      "Epoch 89\n",
      "Loss = 0.5119259407543076 | Training Accuracy = 1.0 | Val Loss = 0.5095950376098705 | Val Accuracy = 1.0\n",
      "Epoch 90\n",
      "Loss = 0.5095950376098705 | Training Accuracy = 1.0 | Val Loss = 0.5069045981741042 | Val Accuracy = 1.0\n",
      "Epoch 91\n",
      "Loss = 0.5069045981741042 | Training Accuracy = 1.0 | Val Loss = 0.5044160269323404 | Val Accuracy = 1.0\n",
      "Epoch 92\n",
      "Loss = 0.5044160269323404 | Training Accuracy = 1.0 | Val Loss = 0.501647984454874 | Val Accuracy = 1.0\n",
      "Epoch 93\n",
      "Loss = 0.501647984454874 | Training Accuracy = 1.0 | Val Loss = 0.49889654482081497 | Val Accuracy = 1.0\n",
      "Epoch 94\n",
      "Loss = 0.49889654482081497 | Training Accuracy = 1.0 | Val Loss = 0.4961339111674233 | Val Accuracy = 1.0\n",
      "Epoch 95\n",
      "Loss = 0.4961339111674233 | Training Accuracy = 1.0 | Val Loss = 0.4933350716714083 | Val Accuracy = 1.0\n",
      "Epoch 96\n",
      "Loss = 0.4933350716714083 | Training Accuracy = 1.0 | Val Loss = 0.4905385411083677 | Val Accuracy = 1.0\n",
      "Epoch 97\n",
      "Loss = 0.4905385411083677 | Training Accuracy = 1.0 | Val Loss = 0.4877200590300614 | Val Accuracy = 1.0\n",
      "Epoch 98\n",
      "Loss = 0.4877200590300614 | Training Accuracy = 1.0 | Val Loss = 0.48487551977152676 | Val Accuracy = 1.0\n",
      "Epoch 99\n",
      "Loss = 0.48487551977152676 | Training Accuracy = 1.0 | Val Loss = 0.48202075362895147 | Val Accuracy = 1.0\n",
      "Epoch 100\n",
      "Loss = 0.48202075362895147 | Training Accuracy = 1.0 | Val Loss = 0.4791275124171236 | Val Accuracy = 1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get preprocessed training and validation data\n",
    "\n",
    "X_train = np.array([\n",
    "    [1, 2, 1, 2],\n",
    "    [2, 4, 2, 4],\n",
    "    [2, 1, 2, 1],\n",
    "    [4, 2, 4, 2],\n",
    "])\n",
    "\n",
    "y_train = np.array([0, 1, 0, 1])\n",
    "X_val = X_train.copy()\n",
    "y_val = y_train.copy()\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "\n",
    "\n",
    "# define neural net\n",
    "model = NN()\n",
    "\n",
    "model.add_layer(Linear(4, 100))\n",
    "model.add_layer(ReLU())\n",
    "model.add_layer(Linear(100, 100))\n",
    "model.add_layer(ReLU())\n",
    "model.add_layer(Linear(100, 2))\n",
    "# model.add_layer(CrossEntropyLoss())\n",
    "# add some layers\n",
    "# YOUR CODE HERE\n",
    "\n",
    "model = train(model, X_train , y_train, minibatch_size=4, epoch=100,\n",
    "           learning_rate=0.1, X_val=X_val, y_val=y_val)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mnist training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.astype(np.int32)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, \n",
    "                                                  test_size=0.25,\n",
    "                                                  shuffle=True,\n",
    "                                                  random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize data\n",
    "\n",
    "def vis(img, label):\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.title(label)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "vis_idx = 57\n",
    "vis(X_val[vis_idx].reshape(-1, 28), y_val[vis_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52500, 784)\n",
      "(17500, 784)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "\n",
    "\n",
    "# define neural net\n",
    "model = NN()\n",
    "\n",
    "model.add_layer(Linear(784, 200))\n",
    "model.add_layer(ReLU())\n",
    "model.add_layer(Linear(200, 100))\n",
    "model.add_layer(ReLU())\n",
    "model.add_layer(Linear(100, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 11/411 [00:00<00:03, 108.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 411/411 [00:05<00:00, 76.83it/s]\n",
      "100%|██████████| 137/137 [00:00<00:00, 143.34it/s]\n",
      "  1%|          | 5/411 [00:00<00:10, 37.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 1.2529499048429034 | Training Accuracy = 0.9119047619047619 | Val Loss = 0.33486900813232284 | Val Accuracy = 0.9048571428571428\n",
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 411/411 [00:08<00:00, 47.31it/s] \n",
      "100%|██████████| 137/137 [00:00<00:00, 202.29it/s]\n",
      "  2%|▏         | 8/411 [00:00<00:07, 50.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 0.38471607497795407 | Training Accuracy = 0.9375428571428571 | Val Loss = 0.21379794952508369 | Val Accuracy = 0.9270285714285714\n",
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 411/411 [00:10<00:00, 40.43it/s]\n",
      "100%|██████████| 137/137 [00:01<00:00, 109.89it/s]\n",
      "  1%|          | 4/411 [00:00<00:10, 37.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 0.3218208808650636 | Training Accuracy = 0.9557142857142857 | Val Loss = 0.18319190430530724 | Val Accuracy = 0.9428\n",
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 411/411 [00:10<00:00, 37.71it/s]\n",
      "100%|██████████| 137/137 [00:00<00:00, 144.00it/s]\n",
      "  0%|          | 2/411 [00:00<00:21, 19.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 0.2883530501652323 | Training Accuracy = 0.9621904761904762 | Val Loss = 0.17376999541934407 | Val Accuracy = 0.9476\n",
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 411/411 [00:10<00:00, 38.91it/s]\n",
      "100%|██████████| 137/137 [00:00<00:00, 166.14it/s]\n",
      "  1%|          | 3/411 [00:00<00:15, 25.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 0.2659920770820246 | Training Accuracy = 0.9669142857142857 | Val Loss = 0.16862663441592105 | Val Accuracy = 0.9507428571428571\n",
      "Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 411/411 [00:11<00:00, 36.92it/s]\n",
      "100%|██████████| 137/137 [00:00<00:00, 154.77it/s]\n",
      "  0%|          | 2/411 [00:00<00:21, 18.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 0.24814440129913334 | Training Accuracy = 0.9704761904761905 | Val Loss = 0.16379874963259897 | Val Accuracy = 0.9525714285714286\n",
      "Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 411/411 [00:09<00:00, 41.14it/s]\n",
      "100%|██████████| 137/137 [00:00<00:00, 168.99it/s]\n",
      "  1%|          | 3/411 [00:00<00:21, 19.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 0.23391864102954305 | Training Accuracy = 0.9734095238095238 | Val Loss = 0.1638611419635391 | Val Accuracy = 0.9556\n",
      "Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 411/411 [00:09<00:00, 43.47it/s]\n",
      "100%|██████████| 137/137 [00:00<00:00, 220.24it/s]\n",
      "  2%|▏         | 10/411 [00:00<00:04, 97.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 0.22252095721629858 | Training Accuracy = 0.9749142857142857 | Val Loss = 0.16084185403067894 | Val Accuracy = 0.9559428571428571\n",
      "Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 411/411 [00:08<00:00, 49.02it/s]\n",
      "100%|██████████| 137/137 [00:00<00:00, 224.59it/s]\n",
      "  2%|▏         | 9/411 [00:00<00:04, 89.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 0.2119703833536249 | Training Accuracy = 0.9762666666666666 | Val Loss = 0.1591696175175984 | Val Accuracy = 0.9569142857142857\n",
      "Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 411/411 [00:07<00:00, 53.66it/s] \n",
      "100%|██████████| 137/137 [00:01<00:00, 110.50it/s]\n",
      "  2%|▏         | 10/411 [00:00<00:04, 97.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 0.2022428492638919 | Training Accuracy = 0.9784 | Val Loss = 0.153988189527163 | Val Accuracy = 0.9572\n",
      "Epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 411/411 [00:07<00:00, 55.15it/s] \n",
      "100%|██████████| 137/137 [00:01<00:00, 76.61it/s]\n",
      "  2%|▏         | 9/411 [00:00<00:04, 87.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 0.19363045617969715 | Training Accuracy = 0.9795047619047619 | Val Loss = 0.14985177679639386 | Val Accuracy = 0.9570285714285715\n",
      "Epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 411/411 [00:04<00:00, 85.33it/s] \n",
      "100%|██████████| 137/137 [00:01<00:00, 93.89it/s] \n",
      "  0%|          | 2/411 [00:00<00:21, 18.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 0.18616874875370876 | Training Accuracy = 0.9801333333333333 | Val Loss = 0.1433311280972805 | Val Accuracy = 0.958\n",
      "Epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 411/411 [00:07<00:00, 58.29it/s] \n",
      "100%|██████████| 137/137 [00:01<00:00, 120.57it/s]\n",
      "  1%|          | 3/411 [00:00<00:18, 22.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 0.1796549122037346 | Training Accuracy = 0.9809714285714286 | Val Loss = 0.1377638530685665 | Val Accuracy = 0.9574857142857143\n",
      "Epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 411/411 [00:06<00:00, 58.72it/s]\n",
      "100%|██████████| 137/137 [00:02<00:00, 67.06it/s]\n",
      "  1%|          | 4/411 [00:00<00:11, 35.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 0.17421439567919683 | Training Accuracy = 0.9827809523809524 | Val Loss = 0.13595316385729078 | Val Accuracy = 0.9575428571428571\n",
      "Epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 411/411 [00:06<00:00, 65.99it/s] \n",
      "100%|██████████| 137/137 [00:00<00:00, 172.88it/s]\n",
      "  0%|          | 2/411 [00:00<00:21, 19.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 0.1683261689812088 | Training Accuracy = 0.9829523809523809 | Val Loss = 0.13293399159993202 | Val Accuracy = 0.9570285714285715\n",
      "Epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 411/411 [00:07<00:00, 52.99it/s] \n",
      "100%|██████████| 137/137 [00:00<00:00, 221.84it/s]\n",
      "  1%|          | 3/411 [00:00<00:15, 26.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 0.16415834967884158 | Training Accuracy = 0.9825904761904762 | Val Loss = 0.13527711277172347 | Val Accuracy = 0.9573714285714285\n",
      "Epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 411/411 [00:08<00:00, 49.13it/s]\n",
      "100%|██████████| 137/137 [00:00<00:00, 187.12it/s]\n",
      "  0%|          | 2/411 [00:00<00:21, 19.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 0.15912474349315564 | Training Accuracy = 0.984 | Val Loss = 0.13355238958309687 | Val Accuracy = 0.9581714285714286\n",
      "Epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 411/411 [00:08<00:00, 46.22it/s]\n",
      "100%|██████████| 137/137 [00:00<00:00, 190.09it/s]\n",
      "  2%|▏         | 9/411 [00:00<00:04, 84.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 0.15553558633982204 | Training Accuracy = 0.9848 | Val Loss = 0.13491016676180703 | Val Accuracy = 0.9578857142857143\n",
      "Epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 411/411 [00:09<00:00, 44.95it/s]\n",
      "100%|██████████| 137/137 [00:01<00:00, 124.44it/s]\n",
      "  2%|▏         | 9/411 [00:00<00:04, 87.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 0.15181354223531127 | Training Accuracy = 0.9882095238095238 | Val Loss = 0.13158451665880988 | Val Accuracy = 0.9608571428571429\n",
      "Epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 411/411 [00:07<00:00, 53.81it/s]\n",
      "100%|██████████| 137/137 [00:01<00:00, 94.94it/s]\n",
      "  2%|▏         | 9/411 [00:00<00:04, 82.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 0.14820329451311767 | Training Accuracy = 0.9870666666666666 | Val Loss = 0.13035920586397987 | Val Accuracy = 0.9603428571428572\n",
      "Epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 411/411 [00:04<00:00, 83.90it/s] \n",
      "100%|██████████| 137/137 [00:02<00:00, 67.62it/s]\n",
      "  1%|          | 3/411 [00:00<00:15, 25.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 0.1441052707296408 | Training Accuracy = 0.9897333333333334 | Val Loss = 0.12622515796537695 | Val Accuracy = 0.9614857142857143\n",
      "Epoch 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 411/411 [00:05<00:00, 70.51it/s] \n",
      "100%|██████████| 137/137 [00:02<00:00, 54.10it/s]\n",
      "  1%|          | 5/411 [00:00<00:08, 45.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 0.14117853813209716 | Training Accuracy = 0.9915619047619048 | Val Loss = 0.12455533409886299 | Val Accuracy = 0.9632571428571428\n",
      "Epoch 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 411/411 [00:09<00:00, 44.37it/s]\n",
      "100%|██████████| 137/137 [00:01<00:00, 87.62it/s] \n",
      "  1%|          | 4/411 [00:00<00:10, 37.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 0.1390297565702088 | Training Accuracy = 0.9937904761904762 | Val Loss = 0.12523105540110524 | Val Accuracy = 0.9635428571428571\n",
      "Epoch 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 411/411 [00:06<00:00, 58.98it/s]\n",
      "100%|██████████| 137/137 [00:00<00:00, 217.16it/s]\n",
      "  1%|          | 3/411 [00:00<00:16, 25.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 0.13731448486104064 | Training Accuracy = 0.9935238095238095 | Val Loss = 0.12476923221775105 | Val Accuracy = 0.9642285714285714\n",
      "Epoch 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 411/411 [00:08<00:00, 49.55it/s] \n",
      "100%|██████████| 137/137 [00:00<00:00, 219.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 0.13578074426497622 | Training Accuracy = 0.9937333333333334 | Val Loss = 0.12654078050126968 | Val Accuracy = 0.9629142857142857\n"
     ]
    }
   ],
   "source": [
    "model = train(model, X_train , y_train, minibatch_size=128, epoch=25,\n",
    "           learning_rate=0.001, X_val=X_val, y_val=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAAD3CAYAAADmIkO7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAFuklEQVR4nO3dv4qUVxzH4XOMSsKU28gyrSBYaLFXYBMU2SsI2olCsLBKoWCRymIbbyCo2CjxD1gI4g2YUgQbBZHYuIWCG1YWToqkCdk5JjP7Ot+dfZ5K9ofveUE+/mQP49bWWgHy7Jv3CwDbEyeEEieEEieEEieEEieEEieEEucCqLX+WGv9rda6WWv9Zd7vw87YP+8XYEf8Xkr5uZTyfSnluzm/CztEnAugtfZrKaXUWldKKeM5vw47xD9rIZQ4IZQ4IZQ4IZRvCC2AWuv+8tef5TellG9qrd+WUrZaa1vzfTNmYXMuhsullD9KKT+VUn74+9eX5/pGzKz6sDVksjkhlDghlDghlDghVPcqpdbqu0UwsNZa3e7rNieEEieEEieEEieEEieEEieEEieEEieEEieEEieEEieEEieEEieEEieEEieEEieEEieEEieEEieEEieEEieEEieEEieEEieEEieEEieEEieEEieEEieEEieEEieEEieEEieEEieEEieEEieEEieEEieE2j/vFyDLgwcPJs5WV1e7v/fFixfd+dWrV7vzO3fudOd7jc0JocQJocQJocQJocQJocQJocQJoWprbfKw1slDdqXxeNydP378eOLsyJEjM529vr7enR87dmzi7N27dzOdnay1Vrf7us0JocQJocQJocQJocQJocQJoXxkbI+5ePFidz7rdUnP1tZWd/7hw4fBzt6NbE4IJU4IJU4IJU4IJU4IJU4IJU4I5Z5zj1laWprb2Wtra935xsbGV3qT3cHmhFDihFDihFDihFDihFDihFDihFDuORfMoUOHuvMTJ04MdvaXfgTg3bt3Bzt7EdmcEEqcEEqcEEqcEEqcEEqcEEqcEMo954I5fvx4d75v3/R/H799+7Y7v3btWnf+5s2bqc/ei2xOCCVOCCVOCCVOCCVOCCVOCCVOCOWec5cZjUbd+YULF7rz8Xg89dkPHz7szm/evDn1s/k3mxNCiRNCiRNCiRNCiRNCiRNCuUrZZY4ePdqdnz59eqbnb25uTpw9ffp0pmfz/9icEEqcEEqcEEqcEEqcEEqcEEqcEMo9Z5iDBw9251euXBn0/CdPnkyc3bt3b9Cz+SebE0KJE0KJE0KJE0KJE0KJE0KJE0K55wxz/vz57vzUqVMzPX99fb07d5eZw+aEUOKEUOKEUOKEUOKEUOKEUOKEUO45wxw+fHjQ579+/bo7v3379qDn89/ZnBBKnBBKnBBKnBBKnBBKnBBKnBDKPeccLC8vT5ytrq4OevaNGze6897P5+TrsjkhlDghlDghlDghlDghlDghlKuUOTh79uzE2Xg8HvTsZ8+eDfp8do7NCaHECaHECaHECaHECaHECaHECaHccw7gwIED3fnJkyenfvbnz5+787W1te78+fPnU5/N12VzQihxQihxQihxQihxQihxQihxQqjaWps8rHXykIlGo1F3/vHjx6mfvbGx0Z2vrKx05y9fvpz6bIbRWqvbfd3mhFDihFDihFDihFDihFDihFDihFA+zzmAc+fODfbsV69edefuMReHzQmhxAmhxAmhxAmhxAmhxAmhXKUM4NKlS4M9+/79+4M9myw2J4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4RyzzmFM2fOdOfLy8tTP/vTp0/d+fXr16d+NruLzQmhxAmhxAmhxAmhxAmhxAmhxAmh3HNOYWlpabBnP3r0qDt///79YGeTxeaEUOKEUOKEUOKEUOKEUOKEUOKEUO45p/Clu8YvfSZzNBpNnN26dWuqd2Lx2JwQSpwQSpwQSpwQSpwQSpwQSpwQqrbWJg9rnTwEdkRrrW73dZsTQokTQokTQokTQokTQokTQokTQokTQokTQokTQokTQokTQokTQokTQokTQokTQokTQokTQokTQokTQokTQokTQnX/a0xgfmxOCCVOCCVOCCVOCCVOCCVOCPUnQ6O2GEAtPrsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize prediction \n",
    "\n",
    "vis_idx = 10\n",
    "pred = model.predict(X_val[vis_idx])\n",
    "vis(X_val[vis_idx].reshape(-1, 28), pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f65bc9451d0>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "t = model.layers[0].W.mean(axis = 1).reshape(28, 28)\n",
    "plt.matshow(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO:\n",
    "1) Add computational graph instead of list, model saving/loading, more optimizers, shedulers loss functions, operations, gpu support, utility tools ...\n",
    "\n",
    "... Or simply use Pytorch/TF/whatever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
